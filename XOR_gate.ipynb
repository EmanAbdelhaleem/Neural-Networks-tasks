{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerLogicGate(tf.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.built = False\n",
    "\n",
    "    def __call__(self, x, train=True):\n",
    "        if not self.built:\n",
    "            self.w1 = tf.Variable(tf.random.normal([2, 2]), name=\"weights1\")\n",
    "            self.b1 = tf.Variable(tf.zeros([2]), name=\"bias1\")\n",
    "            self.w2 = tf.Variable(tf.random.normal([2, 1]), name=\"weights2\")\n",
    "            self.b2 = tf.Variable(tf.zeros([1]), name=\"bias2\")\n",
    "            self.built = True\n",
    "\n",
    "        hidden = tf.sigmoid(tf.matmul(x, self.w1) + self.b1)\n",
    "        output = tf.sigmoid(tf.matmul(hidden, self.w2) + self.b2)\n",
    "        return output\n",
    "\n",
    "def compute_loss(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "\n",
    "def train_model(model, x_train, y_train, learning_rate=0.5, epochs=5000):\n",
    "    for epoch in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x_train)\n",
    "            loss = compute_loss(y_pred, y_train)\n",
    "\n",
    "        grads = tape.gradient(loss, model.variables)\n",
    "        for g, v in zip(grads, model.variables):\n",
    "            v.assign_sub(learning_rate * g)\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "            acc = compute_accuracy(model, x_train, y_train)\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.numpy():.4f}, Accuracy: {acc:.4f}\")\n",
    "\n",
    "def compute_accuracy(model, x, y_true):\n",
    "    y_pred = model(x, train=False)\n",
    "    y_pred_rounded = tf.round(y_pred)\n",
    "    correct = tf.equal(y_pred_rounded, y_true)\n",
    "    return tf.reduce_mean(tf.cast(correct, tf.float32)).numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_table = np.array([[0, 0, 0],\n",
    "                      [1, 0, 1],\n",
    "                      [0, 1, 1],\n",
    "                      [1, 1, 0]], dtype=np.float32)\n",
    "\n",
    "x_train = xor_table[:, :2]\n",
    "y_train = xor_table[:, 2:]\n",
    "\n",
    "model = TwoLayerLogicGate()\n",
    "train_model(model, x_train, y_train)\n",
    "\n",
    "w1 = model.w1.numpy()\n",
    "w2 = model.w2.numpy()\n",
    "b1 = model.b1.numpy()\n",
    "b2 = model.b2.numpy()[0]\n",
    "print(f\"\\nLearned weights for first layer:\\n{w1}\")\n",
    "print(f\"Learned weights for second layer:\\n{w2}\")\n",
    "print(f\"Learned bias for first layer: {b1}\")\n",
    "print(f\"Learned bias for second layer: {b2}\\n\")\n",
    "\n",
    "y_pred = model(x_train, train=False).numpy().round().astype(np.uint8)\n",
    "print(\"Predicted Truth Table:\")\n",
    "print(np.column_stack((xor_table[:, :2], y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
