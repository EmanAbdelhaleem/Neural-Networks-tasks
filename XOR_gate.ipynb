{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerLogicGate(tf.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.built = False\n",
    "\n",
    "    def __call__(self, x, train=True):\n",
    "        if not self.built:\n",
    "            self.w1 = tf.Variable(tf.random.normal([2, 2]), name=\"weights1\")\n",
    "            self.b1 = tf.Variable(tf.zeros([2]), name=\"bias1\")\n",
    "            self.w2 = tf.Variable(tf.random.normal([2, 1]), name=\"weights2\")\n",
    "            self.b2 = tf.Variable(tf.zeros([1]), name=\"bias2\")\n",
    "            self.built = True\n",
    "\n",
    "        hidden = tf.sigmoid(tf.matmul(x, self.w1) + self.b1)\n",
    "        output = tf.sigmoid(tf.matmul(hidden, self.w2) + self.b2)\n",
    "        return output\n",
    "\n",
    "def compute_loss(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "\n",
    "def train_model(model, x_train, y_train, learning_rate=0.5, epochs=5000):\n",
    "    for epoch in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x_train)\n",
    "            loss = compute_loss(y_pred, y_train)\n",
    "\n",
    "        grads = tape.gradient(loss, model.variables)\n",
    "        for g, v in zip(grads, model.variables):\n",
    "            v.assign_sub(learning_rate * g)\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "            acc = compute_accuracy(model, x_train, y_train)\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.numpy():.4f}, Accuracy: {acc:.4f}\")\n",
    "\n",
    "def compute_accuracy(model, x, y_true):\n",
    "    y_pred = model(x, train=False)\n",
    "    y_pred_rounded = tf.round(y_pred)\n",
    "    correct = tf.equal(y_pred_rounded, y_true)\n",
    "    return tf.reduce_mean(tf.cast(correct, tf.float32)).numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742964572.292106   10324 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1209 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:64:00.0, compute capability: 8.9\n",
      "W0000 00:00:1742964572.441176   10324 gpu_backend_lib.cc:579] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  ipykernel_launcher.runfiles/cuda_nvcc\n",
      "  ipykern/cuda_nvcc\n",
      "  \n",
      "  /usr/local/cuda\n",
      "  /home/eman/anaconda3/envs/tf_env/lib/python3.11/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc\n",
      "  /home/eman/anaconda3/envs/tf_env/lib/python3.11/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc\n",
      "  /home/eman/anaconda3/envs/tf_env/lib/python3.11/site-packages/tensorflow/python/platform/../../cuda\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "W0000 00:00:1742964572.442714   10324 gpu_backend_lib.cc:617] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "error: libdevice not found at ./libdevice.10.bc\n",
      "2025-03-26 06:49:32.443121: E tensorflow/compiler/mlir/tools/kernel_gen/tf_framework_c_interface.cc:228] INTERNAL: Generating device code failed.\n",
      "2025-03-26 06:49:32.444499: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: JIT compilation failed.\n",
      "2025-03-26 06:49:32.444545: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: UNKNOWN: JIT compilation failed.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "{{function_node __wrapped__Sigmoid_device_/job:localhost/replica:0/task:0/device:GPU:0}} JIT compilation failed. [Op:Sigmoid] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnknownError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m y_train = xor_table[:, \u001b[32m2\u001b[39m:]\n\u001b[32m      9\u001b[39m model = TwoLayerLogicGate()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m w1 = model.w1.numpy()\n\u001b[32m     13\u001b[39m w2 = model.w2.numpy()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, x_train, y_train, learning_rate, epochs)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tf.GradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m         y_pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m         loss = compute_loss(y_pred, y_train)\n\u001b[32m     30\u001b[39m     grads = tape.gradient(loss, model.variables)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mTwoLayerLogicGate.__call__\u001b[39m\u001b[34m(self, x, train)\u001b[39m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mself\u001b[39m.b2 = tf.Variable(tf.zeros([\u001b[32m1\u001b[39m]), name=\u001b[33m\"\u001b[39m\u001b[33mbias2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mself\u001b[39m.built = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m hidden = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mw1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mb1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m output = tf.sigmoid(tf.matmul(hidden, \u001b[38;5;28mself\u001b[39m.w2) + \u001b[38;5;28mself\u001b[39m.b2)\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_env/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[39m, in \u001b[36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     87\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m   bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m     90\u001b[39m   bound_arguments.apply_defaults()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_env/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:6002\u001b[39m, in \u001b[36mraise_from_not_ok_status\u001b[39m\u001b[34m(e, name)\u001b[39m\n\u001b[32m   6000\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_from_not_ok_status\u001b[39m(e, name) -> NoReturn:\n\u001b[32m   6001\u001b[39m   e.message += (\u001b[33m\"\u001b[39m\u001b[33m name: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m6002\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m core._status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mUnknownError\u001b[39m: {{function_node __wrapped__Sigmoid_device_/job:localhost/replica:0/task:0/device:GPU:0}} JIT compilation failed. [Op:Sigmoid] name: "
     ]
    }
   ],
   "source": [
    "xor_table = np.array([[0, 0, 0],\n",
    "                      [1, 0, 1],\n",
    "                      [0, 1, 1],\n",
    "                      [1, 1, 0]], dtype=np.float32)\n",
    "\n",
    "x_train = xor_table[:, :2]\n",
    "y_train = xor_table[:, 2:]\n",
    "\n",
    "model = TwoLayerLogicGate()\n",
    "train_model(model, x_train, y_train)\n",
    "\n",
    "w1 = model.w1.numpy()\n",
    "w2 = model.w2.numpy()\n",
    "b1 = model.b1.numpy()\n",
    "b2 = model.b2.numpy()[0]\n",
    "print(f\"\\nLearned weights for first layer:\\n{w1}\")\n",
    "print(f\"Learned weights for second layer:\\n{w2}\")\n",
    "print(f\"Learned bias for first layer: {b1}\")\n",
    "print(f\"Learned bias for second layer: {b2}\\n\")\n",
    "\n",
    "y_pred = model(x_train, train=False).numpy().round().astype(np.uint8)\n",
    "print(\"Predicted Truth Table:\")\n",
    "print(np.column_stack((xor_table[:, :2], y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
